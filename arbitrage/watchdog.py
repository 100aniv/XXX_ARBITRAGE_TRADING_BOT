#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Watchdog System (PHASE D11)
===========================

ì¥ì‹œê°„ ìš´ìš© ì¤‘ ë¹„ì •ìƒ ìƒí™©ì„ ê°ì‹œí•˜ê³  ê²½ê³ /ì¡°ì¹˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ëª¨ë“ˆ.

íŠ¹ì§•:
- ë©”íŠ¸ë¦­ ê¸°ë°˜ ìƒíƒœ íŒë‹¨
- ë‹¨ê³„ì  ê²½ê³  (WARN â†’ ERROR â†’ SHUTDOWN)
- ì„ íƒì  graceful shutdown ìš”ì²­
- AlertSystemê³¼ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ë™
"""

import logging
from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List
from enum import Enum

logger = logging.getLogger(__name__)


class AlertLevel(Enum):
    """ê²½ê³  ë ˆë²¨"""
    OK = "OK"
    WARN = "WARN"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"


@dataclass
class AlertEvent:
    """ê²½ê³  ì´ë²¤íŠ¸"""
    level: AlertLevel
    component: str
    message: str
    metric_name: Optional[str] = None
    metric_value: Optional[float] = None
    threshold: Optional[float] = None


@dataclass
class WatchdogConfig:
    """ì›Œì¹˜ë… ì„¤ì •"""
    # WebSocket ê°ì‹œ
    max_ws_lag_ms: float = 5000.0           # ìµœëŒ€ WS ì§€ì—° (ms)
    ws_lag_warn_threshold_ms: float = 2000.0
    
    # Redis heartbeat ê°ì‹œ
    max_redis_heartbeat_age_ms: float = 30000.0  # ìµœëŒ€ 30ì´ˆ
    redis_heartbeat_warn_threshold_ms: float = 15000.0
    
    # ë£¨í”„ ì§€ì—° ê°ì‹œ
    max_loop_latency_ms: float = 5000.0
    loop_latency_warn_threshold_ms: float = 2000.0
    
    # ì•ˆì „ ê²€ì¦ ê°ì‹œ
    max_safety_rejections_per_minute: int = 10
    
    # Live ëª¨ë“œ ê°ì‹œ
    max_live_errors_per_minute: int = 5
    
    # ë¦¬ì†ŒìŠ¤ ê°ì‹œ (sys_monitorì™€ ì—°ë™)
    max_cpu_pct: float = 90.0
    max_rss_mb: float = 2048.0
    
    # D12: íŠœë‹ & Auto-reset
    warn_reset_cycles: int = 5              # WARN ìƒíƒœ ìë™ ë¦¬ì…‹ ì‚¬ì´í´ ìˆ˜
    error_reset_cycles: int = 20            # ERROR ìƒíƒœ ìë™ ë¦¬ì…‹ ì‚¬ì´í´ ìˆ˜
    cooldown_after_critical: float = 60.0   # CRITICAL í›„ ì¿¨ë‹¤ìš´ (ì´ˆ)


@dataclass
class WatchdogStatus:
    """ì›Œì¹˜ë… ìƒíƒœ"""
    is_healthy: bool = True
    alerts: List[AlertEvent] = field(default_factory=list)
    last_check_ts: Optional[float] = None
    consecutive_errors: int = 0
    should_shutdown: bool = False
    shutdown_reason: Optional[str] = None


class Watchdog:
    """ì›Œì¹˜ë… ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: Optional[WatchdogConfig] = None):
        """
        Args:
            config: WatchdogConfig ì¸ìŠ¤í„´ìŠ¤
        """
        self.config = config or WatchdogConfig()
        self.status = WatchdogStatus()
        self.metrics_history: Dict[str, List[float]] = {}
        self.rejection_count_per_minute = 0
        self.error_count_per_minute = 0
        self.last_minute_reset_ts = 0.0
        
        # D12: Auto-reset ìƒíƒœ
        self.warn_cycle_count = 0           # WARN ìƒíƒœ ì‚¬ì´í´ ì¹´ìš´íŠ¸
        self.error_cycle_count = 0          # ERROR ìƒíƒœ ì‚¬ì´í´ ì¹´ìš´íŠ¸
        self.last_critical_ts = 0.0         # ë§ˆì§€ë§‰ CRITICAL ì‹œê°„
        self.consecutive_warn_count = 0     # ì—°ì† WARN ê²½ê³  ìˆ˜
    
    def update_metrics(self, metrics: Dict[str, Any]) -> None:
        """
        ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        
        Args:
            metrics: MetricsCollector.get_all_metrics() ê²°ê³¼
        """
        import time
        
        current_ts = time.time()
        
        # ë¶„ ë‹¨ìœ„ ì¹´ìš´í„° ë¦¬ì…‹
        if current_ts - self.last_minute_reset_ts > 60:
            self.rejection_count_per_minute = 0
            self.error_count_per_minute = 0
            self.last_minute_reset_ts = current_ts
        
        # ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ì €ì¥
        for key, value in metrics.items():
            if isinstance(value, (int, float)):
                if key not in self.metrics_history:
                    self.metrics_history[key] = []
                self.metrics_history[key].append(value)
                # ìµœê·¼ 100ê°œë§Œ ë³´ê´€
                if len(self.metrics_history[key]) > 100:
                    self.metrics_history[key].pop(0)
        
        self.status.last_check_ts = current_ts
    
    def evaluate(self, metrics: Dict[str, Any]) -> WatchdogStatus:
        """
        í˜„ì¬ ìƒíƒœ í‰ê°€
        
        Args:
            metrics: MetricsCollector.get_all_metrics() ê²°ê³¼
        
        Returns:
            WatchdogStatus
        """
        self.status.alerts = []
        self.status.is_healthy = True
        
        # WebSocket ì§€ì—° í™•ì¸
        ws_lag = metrics.get("ws_lag_ms", 0.0)
        if ws_lag > self.config.max_ws_lag_ms:
            self.status.alerts.append(AlertEvent(
                level=AlertLevel.ERROR,
                component="WebSocket",
                message=f"WS lag critical: {ws_lag:.1f}ms > {self.config.max_ws_lag_ms}ms",
                metric_name="ws_lag_ms",
                metric_value=ws_lag,
                threshold=self.config.max_ws_lag_ms
            ))
            self.status.is_healthy = False
        elif ws_lag > self.config.ws_lag_warn_threshold_ms:
            self.status.alerts.append(AlertEvent(
                level=AlertLevel.WARN,
                component="WebSocket",
                message=f"WS lag warning: {ws_lag:.1f}ms > {self.config.ws_lag_warn_threshold_ms}ms",
                metric_name="ws_lag_ms",
                metric_value=ws_lag,
                threshold=self.config.ws_lag_warn_threshold_ms
            ))
        
        # Redis heartbeat í™•ì¸
        redis_age = metrics.get("redis_heartbeat_age_ms", 0.0)
        if redis_age > self.config.max_redis_heartbeat_age_ms:
            self.status.alerts.append(AlertEvent(
                level=AlertLevel.ERROR,
                component="Redis",
                message=f"Redis heartbeat stale: {redis_age:.1f}ms > {self.config.max_redis_heartbeat_age_ms}ms",
                metric_name="redis_heartbeat_age_ms",
                metric_value=redis_age,
                threshold=self.config.max_redis_heartbeat_age_ms
            ))
            self.status.is_healthy = False
        elif redis_age > self.config.redis_heartbeat_warn_threshold_ms:
            self.status.alerts.append(AlertEvent(
                level=AlertLevel.WARN,
                component="Redis",
                message=f"Redis heartbeat aging: {redis_age:.1f}ms > {self.config.redis_heartbeat_warn_threshold_ms}ms",
                metric_name="redis_heartbeat_age_ms",
                metric_value=redis_age,
                threshold=self.config.redis_heartbeat_warn_threshold_ms
            ))
        
        # ë£¨í”„ ì§€ì—° í™•ì¸
        loop_latency = metrics.get("loop_latency_ms", 0.0)
        if loop_latency > self.config.max_loop_latency_ms:
            self.status.alerts.append(AlertEvent(
                level=AlertLevel.ERROR,
                component="MainLoop",
                message=f"Loop latency critical: {loop_latency:.1f}ms > {self.config.max_loop_latency_ms}ms",
                metric_name="loop_latency_ms",
                metric_value=loop_latency,
                threshold=self.config.max_loop_latency_ms
            ))
            self.status.is_healthy = False
        elif loop_latency > self.config.loop_latency_warn_threshold_ms:
            self.status.alerts.append(AlertEvent(
                level=AlertLevel.WARN,
                component="MainLoop",
                message=f"Loop latency warning: {loop_latency:.1f}ms > {self.config.loop_latency_warn_threshold_ms}ms",
                metric_name="loop_latency_ms",
                metric_value=loop_latency,
                threshold=self.config.loop_latency_warn_threshold_ms
            ))
        
        # ì•ˆì „ ê²€ì¦ ê±°ë¶€ í™•ì¸
        safety_rejections = metrics.get("safety_rejections_count", 0)
        if safety_rejections > self.config.max_safety_rejections_per_minute:
            self.status.alerts.append(AlertEvent(
                level=AlertLevel.WARN,
                component="Safety",
                message=f"Safety rejections high: {safety_rejections} > {self.config.max_safety_rejections_per_minute}",
                metric_name="safety_rejections_count",
                metric_value=float(safety_rejections),
                threshold=float(self.config.max_safety_rejections_per_minute)
            ))
        
        # ERROR ë ˆë²¨ ê²½ê³ ê°€ ìˆìœ¼ë©´ ìƒíƒœ ì—…ë°ì´íŠ¸
        error_alerts = [a for a in self.status.alerts if a.level == AlertLevel.ERROR]
        warn_alerts = [a for a in self.status.alerts if a.level == AlertLevel.WARN]
        
        if error_alerts:
            self.status.is_healthy = False
            self.status.consecutive_errors += 1
            self.error_cycle_count += 1
            self.warn_cycle_count = 0  # ERROR ë°œìƒ ì‹œ WARN ì¹´ìš´íŠ¸ ë¦¬ì…‹
            
            # D12: ERROR ìƒíƒœ ìë™ ë¦¬ì…‹ (error_reset_cycles í›„)
            if self.error_cycle_count >= self.config.error_reset_cycles:
                self.soft_reset()
            
            # ì—°ì† ERROR 3íšŒ ì´ìƒ â†’ CRITICAL (graceful shutdown ìš”ì²­)
            if self.status.consecutive_errors >= 3:
                self.status.should_shutdown = True
                self.status.shutdown_reason = f"Consecutive errors: {self.status.consecutive_errors}"
                self.status.alerts.append(AlertEvent(
                    level=AlertLevel.CRITICAL,
                    component="Watchdog",
                    message=f"Requesting graceful shutdown: {self.status.shutdown_reason}"
                ))
                # CRITICAL ì‹œê°„ ê¸°ë¡
                import time
                self.last_critical_ts = time.time()
        elif warn_alerts:
            # WARNë§Œ ìˆëŠ” ê²½ìš°
            self.warn_cycle_count += 1
            self.error_cycle_count = 0  # WARN ìƒíƒœì—ì„œëŠ” ERROR ì¹´ìš´íŠ¸ ë¦¬ì…‹
            self.consecutive_warn_count = len(warn_alerts)
            
            # D12: WARN ìƒíƒœ ìë™ ë¦¬ì…‹ (warn_reset_cycles í›„)
            if self.warn_cycle_count >= self.config.warn_reset_cycles:
                self.soft_reset()
        else:
            # ì •ìƒ ìƒíƒœ
            self.status.consecutive_errors = 0
            self.warn_cycle_count = 0
            self.error_cycle_count = 0
            self.consecutive_warn_count = 0
        
        return self.status
    
    def get_status_summary(self) -> str:
        """ìƒíƒœ ìš”ì•½ ë¬¸ìì—´"""
        if self.status.should_shutdown:
            return f"ğŸ”´ WATCHDOG CRITICAL - Shutdown requested: {self.status.shutdown_reason}"
        elif not self.status.is_healthy:
            error_count = len([a for a in self.status.alerts if a.level == AlertLevel.ERROR])
            return f"ğŸŸ  WATCHDOG ERROR ({error_count} errors)"
        elif self.status.alerts:
            warn_count = len([a for a in self.status.alerts if a.level == AlertLevel.WARN])
            return f"ğŸŸ¡ WATCHDOG WARN ({warn_count} warnings)"
        else:
            return "ğŸŸ¢ WATCHDOG OK"
    
    def get_alert_summary(self) -> str:
        """ê²½ê³  ìš”ì•½ ë¬¸ìì—´"""
        if not self.status.alerts:
            return ""
        
        lines = []
        for alert in self.status.alerts:
            lines.append(f"  [{alert.level.value}] {alert.component}: {alert.message}")
        
        return "\n".join(lines)
    
    def soft_reset(self) -> None:
        """
        ì†Œí”„íŠ¸ ë¦¬ì…‹ (ë¹„íŒŒê´´ì  ìƒíƒœ ì´ˆê¸°í™”)
        
        D12: ì¥ì‹œê°„ ìš´ì˜ ì¤‘ ê²½ê³  ìƒíƒœì—ì„œ ìë™ ë³µêµ¬
        - ì¹´ìš´í„° ì´ˆê¸°í™”
        - ê²½ê³  ìƒíƒœ ìœ ì§€ (íˆìŠ¤í† ë¦¬)
        - ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì˜í–¥ ì—†ìŒ
        """
        logger.info("[Watchdog] Soft reset triggered (auto-recovery)")
        self.warn_cycle_count = 0
        self.error_cycle_count = 0
        self.consecutive_warn_count = 0
        # consecutive_errorsëŠ” ìœ ì§€ (CRITICAL íŒë‹¨ìš©)
