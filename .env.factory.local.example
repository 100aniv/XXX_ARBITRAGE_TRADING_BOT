# Factory-only local environment template (never commit real secrets)
# Copy to .env.factory.local and fill values locally.
# Docs: ops/factory/README.md

# ===== LLM API Keys (required) =====
ANTHROPIC_API_KEY=
OPENAI_API_KEY=

# ===== Container-network service endpoints =====
POSTGRES_HOST=arbitrage-postgres
POSTGRES_PORT=5432
REDIS_HOST=arbitrage-redis
REDIS_PORT=6379

# ===== Provider Mapping =====
# Default: Aider=OpenAI, Claude Code=Anthropic
# Override to swap (e.g. AIDER_PROVIDER=anthropic to use Claude via Aider)
AIDER_PROVIDER=openai
CLAUDE_CODE_PROVIDER=anthropic

# ===== Per-Tier Model Names =====
# Use your account's actual model IDs. Examples below.
# OpenAI examples: gpt-4.1-mini, gpt-4.1, o3, o4-mini
# Anthropic examples: claude-sonnet-4-20250514, claude-opus-4-20250514
# Leave blank to use policy defaults (DEFAULT_MODELS in supervisor.py).
AIDER_MODEL_LOW=
AIDER_MODEL_MID=
AIDER_MODEL_HIGH=
CLAUDE_CODE_MODEL_LOW=
CLAUDE_CODE_MODEL_MID=
CLAUDE_CODE_MODEL_HIGH=

# ===== General Model Override (overrides per-tier if set) =====
# Leave blank to use per-tier or policy defaults.
AIDER_MODEL=
CLAUDE_CODE_MODEL=

# ===== Tier Cap (운영 기본값: high) =====
# Restrict max model tier per agent: low|mid|high
# Set to 'mid' to block expensive models during development.
AIDER_MODEL_MAX_TIER=high
CLAUDE_CODE_MODEL_MAX_TIER=high

# ===== Smart Router Settings =====
# Intent mode: keyword (deterministic, LLM-free)
ROUTER_INTENT_MODE=keyword
# Escalation: Gate 실패 시 1회 tier 상향 재시도
ROUTER_ESCALATE_ON_GATE_FAIL=1
# Max escalation steps (mid->high = 1 step)
ROUTER_ESCALATE_MAX_STEP=1
